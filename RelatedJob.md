# 大数据相关岗位调研

# ****大数据开发工程师****

## 一. [阿里巴巴集团](https://www.liepin.com/company/1072424/) 深圳-南山区 ****15-30k****

### 职责描述：

如果你想参与阿里大数据的采集、存储、处理，通过分布式大数据平台加工数据，支持业务管理决策，
如果你想参与阿里大数据体系的模型设计、开发、维护，通过元数据、质量体系有效的管理和组织EB级的数据，
如果你想参与阿里大数据产品的研发，发挥你的商业sense，通过数据分析和算法来洞察数据背后的机会，来探索大数据商业化，
如果你想接触大数据处理与应用的技术和平台，获得大数据浪潮之巅的各类大牛的指导，
那就加入我们吧！

### 任职要求：

~~如果你所学专业是计算机、数学、统计、数据科学与大数据技术等相关专业；~~

- 如果你有强的动手能力和学习能力，熟悉一门**数据处理语言**，如SQL、JAVA、Python、Perl等，熟悉unix或者**linux**操作；
- 如果你具备扎实的专业基础，良好的沟通能力和团队合作，主动积极，乐于面对挑战；
- 如果你有参与过**数据处理、分析、挖掘**等相关项目更好；
- 如果你对Hadoop、Hive、Hbase等**分布式平台**有一定的理解更好；

那么成为数据工程师吧，这里就是你的舞台。

## 二. [迅雷](https://www.liepin.com/company/856639/) 深圳-南山区  ****18-30k·15薪****

### 岗位职责

1、负责技术**方案和架构**设计，包含**技术架构**和**数据架构**；
2、负责大数据平台开发过程中的**技术攻关**和关键设计。

### 岗位要求

1、有**分布式大数据平台开发项目经验**；
2、有Hadoop、Spark等平台的**海量数据处理**经验；
3、熟练掌握Hadoop、hive、Spark、Flink、Hbase、Impala、Druid、clickhouse、ElasticSearch、Kylin技术栈中一种及以上；
4、熟练掌握**数据架构设计**、数据库设计及数据建模；
5、对大数据技术和大数据演进有深刻认识；
6、具备开发、部署、调优Hadoop生态环境项目经验；
7、熟练掌握java**语言**，熟悉python、scala、go、rust更佳。

## 三. [华为云计算技术有限公司](https://www.liepin.com/company/12255771/) 深圳-龙岗区 ****20-40k·16薪****

### 岗位职责：

1.负责大数据应用项目的**可行性分析**，制定软件开发、实施计划并亲自落实、执行；组织、协调软件项目所需的资源，及时解决软件项目开发、实施中遇到的各种问题；
2.利用目前正在发展的大数据分布式平台前沿技术的应用，**开展大数据相关项目**；
3.负责大数据系统架构，业界**数据仓库建模**及新的建模方法的发展；
4.参与对数据应用的**开发与维护**；
5.理解业务诉求，转化为对数据的**建模**，帮助大数据开发人员更好的理解业务需求；管理跟进数据开发和业务分析为主的项目,完成各项目例行报告汇总和整理;
6.与公司内部各部门进行沟通，协调各项资源，确保项目整体成功；

### 职位要求：

1.本科及以上学历，计算机或数学相关专业；
2.熟悉hadoop、hive、spark、Kafka等应用；
3.优秀的团队协作、解决问题的能力

## [华为](https://www.liepin.com/company/954482/) 深圳-龙岗区 ****20-40k·14薪****

### 职责描述：

1、负责华为云直播、点播、转码、RTC等视频云服务的实时和**离线数据仓库**和**数据湖**的构建和开发，构建云视频智能音视频数据平台
2、负责华为云视频各云服务的实时或离线数据指标的数据建模、设计和开发
3、负责华为云视频大数据相关组件的开发、维护和优化，参与核心技术问题攻坚、疑难问题解决

### 职位要求

1. 具有良好的抽象设计和**数据建模**能力，思路清晰、善于思考，拥有独立解决问题的能力，具备良好的团队合作精神
2. 熟练掌握Java/Scala语言，掌握多线程、网络编程、异步，熟悉JVM内存结构与GC算法调优
3. 熟悉常见的**算法**和数据结构，能够参与数据模型设计、ETL开发、OLAP开发等，有实时数仓建设经验的优先
4. 熟悉Hadoop、Hive、Spark、Kafka、Hbase、Flink、Elasticsearch、Clickhouse等大数据组件的优先

## [深信服科技股份有限公司](https://www.liepin.com/company/844660/) 深圳-南山区  ****20-40k·16薪****

### 岗位职责:

1、负责大数据平台组件以及承载业务工作流的性能优化
2、负责依据业务需要，针对大数据平台组件进行必要的可靠性、功能性改进

### 岗位描述:

1、扎实计算机基础和算法数据结构功底，愿意尝试新技术和挑战。
2、熟悉并掌握一门或多门语言(Python、Java、Go、Scala)的使用；
3、熟悉ES、Flink，Spark，Kafka，Pulsar，Trino等组件中两个及以上的架构和原理，并可熟练使用
4、具备中大型项目设计能力，有系统优化经验者优先，参与开源社区贡献者优先

## [北京字跳网络技术有限公司](https://www.liepin.com/company/12002817/) 深圳-南山区 ****25-50k·15薪****

职责描述：
数据平台后端开发/大数据开发/算法工程师，Base北京/深圳

任职要求：
符合下列任一条件：
1、熟练使用Java/Scala/Python/Go等任一语言进行后端开发；
2、熟练使用SQL、Python、Java等工具进行大型数据分析及建模；
3、熟练使用Hadoop、Hive、Spark、Flink等组件进行大数据场景数据开发。
4、具备扎实的编码能力和数据结构、算法能力，熟悉常见的机器学习/深度学习算法，熟练使用相关工具。

## [华为](https://www.liepin.com/company/954482/)_问界 深圳 ****20-40k·15薪****

目前华为车业务发展迅速，和小康深度合作的问界M5六月突破7000，大定突破1万。发布的问界M7，发布后的4个小时订单更是突破2万，欢迎有志之士加入。

工作内容：
华为智能车联网云服务相关业务（热门风口行业，业务大发展中），从事车联网、大数据平台和大数据分析等云服务的设计与开发。
新服务、新技术、新架构、业务极具创新性且有挑战，锻炼机会多多。

技术要求：
能够熟练使用以下一项或多项技术：
**云服务技术**、**微服务**、Java开发、大数据（Kafka、HBase、Flink、Spark等）

招聘类型和说明：招华为OD员工（除了配股这点有差异之外，工资奖金管理办公场地等与华为员工一致），与华为牛人共事，随业务快速发展而持续锻炼成长，值得选择！

**其他信息**语言要求：英语

## [华为云计算技术有限公司](https://www.liepin.com/company/12255771/) 深圳 ****20-30k****

目前的岗位是OD，我们组最终目标是要把OD转正，这也是招聘绩效的一部分，本组OD转正率是75%，并在持续上升。
岗位比较多样，有对标开源社区的**组件性能开发**，例如HBase Hadoop spark hive等，
还有对标业务的**业务开发**，例如数据清洗，数据治理，数据中台等。
当然也有服务**后端开发**，就是针对客户的实际业务场景进行功能开发。

# ****大数据开发分析师****

## [华为](https://www.liepin.com/company/954482/) 深圳 ****20-40k·14薪****

### 岗位职责

#华为Cloud BU面向21届/22届应届生火热进行中，毕业时间：2021年-2022年12月30日，工作地深圳，北京，成都，杭州。

1.参与从客户需求到软件产品定义、架构设计、模块设计以及开发实现等研发环节；
2.基于敏捷、Devops、开源等先进的软件设计开发模式，为客户快速交付具有竞争力的产品；

### 岗位要求

1.计算机、通信、软件工程等相关专业本科及以上学历；
2.熟悉Golang/C/C++/Java/Python等一种或多种编程语言，有良好的编程习惯；
3.热爱编程，计算机基础知识扎实，熟悉常用数据结构，对算法有一定了解；
4.熟悉操作系统原理，TCP/IP协议及互联网常见应用和协议的原理优先；
5.良好的学习能力、沟通能力、适应能力、责任心强，能够在压力下独立解决。

# ****大数据运维工程师****

## [奇富科技](https://www.liepin.com/company/8890047/) 深圳-福田区 ****20-30k****

### 岗位职责：

1、负责公司大数据平台的部署、管理、优化、监控报警。持续对大数据平台进行优化；
2、负责大数据平台日常运维管理、服务监控、故障处理、集群性能和资源利用率优化，集群常见问题能迅速定位，为开发人员提供技术支持；
3、负责大数据平台服务器配置选型、集群网络优化等相关工作；
4、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；
5、开发大数据自动化运维、监控报警、故障处理相关脚本和工具。

### 任职资格：

1、熟悉Linux(redhat/centos)**软硬件环境**、**系统管理和优化**，熟练部署、优化各种常用服务；
2、熟悉Hadoop大数据生态圈，包括但不限于CDH/HDFS/YARN/Hive/Hbase/zookeeper/Spark/等；
3、熟练掌握Hadoop组件的安装部署、升级扩容、性能监控以及配置调优；
4、有运维自动化、监控系统、大数据运维工作等开发经验优先考虑；
5、有大数据开发经验和阅读源码能力者优先。
